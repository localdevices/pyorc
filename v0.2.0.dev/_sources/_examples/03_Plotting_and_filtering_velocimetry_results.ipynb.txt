{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4df4e0f",
   "metadata": {},
   "source": [
    "## Immersive plotting and analyzing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e90b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pyorc\n",
    "from matplotlib.colors import Normalize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2880e563",
   "metadata": {},
   "source": [
    "You have a result stored in a NetCDF file after running notebook 02. Now you want to see if the results seem to make sense, and further analyze these. Especially post-processing of your results with filter is an essential step in most velocimetry analyses, given that sometimes hardly any tracers are visible, and only spuriously correlated results were found. With some intelligence these suspicious velocities can be removed, and `pyorc` has many methods available to do that. Most of these can be applied without any parameter changes for a good results. \n",
    "\n",
    "Let's first have a look at the file structure. We can simply use the `xarray` API to open the result file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0789d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"ngwerere/ngwerere_piv.nc\")\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd99b1",
   "metadata": {},
   "source": [
    "As you can see, we have lots of coordinate variables at our disposal, these can be used in turn to plot our data in a local projection, with our bounding box top-left corner at the top-left. The `x` and `y` axes hold the local coordinates. We can also use the UTM35S coordinates, stored in `xs` and `ys`, the longitude and latitude coordinates stored in `lon` and `lat`, or....(very cool) the original row and column coordinate of the camera's objective. This allows us to plot the results as an augmented reality view.\n",
    "\n",
    "In the data variables, we see `v_x` and `v_y` for the x-directional and y-directional velocity, measured long the `x` and `y` axis of the local coordinate system. Furthermore we see the `s2n` variable containing the signal to noise ratio computed by the underlying used library OpenPIV. This ratio is computed as the ratio between the highest correlation and the second highest correlation found in the surroundings of each window. We also store the highest correlation found in the variable `corr`. As this is done for each frame to frame pair, the dataset contain 124 time steps, since we extract 125 frames.\n",
    "\n",
    "Because we used a 0.01 resolution and a 25 pixel interrogation window, and `pyorc` typically uses an overlap between windows of 50%, the `y` and `x` coordinates have a spacing of `25 * 0.01 * 0.5 = 0.125 cm` (rounded to 0.13).\n",
    "\n",
    "Finally, a lot of attributes are stored in a serializable form, so that the dataset can be stored in NetCDF, and the camera configuration and other information needed can be used after loading.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8466af3",
   "metadata": {},
   "source": [
    "### Plotting in local projection\n",
    "Both a frames `DataArray` and a velocimetry `Dataset` have plotting functionalities that can be used to combine information into a plot. The default is to plot data in the local projection that follows the area of interest bounding box, but geographical plots or camera perspectives can also be plotted. Let's start with an rgb frame with the PIV results on top. We cannot plot the time dimension, so we apply a `mean` reducer first.\n",
    "\n",
    "Note that whilst plotting velocimetry results, we can supply `kwargs_scalar` and `kwargs_quiver`. These are meant to pass arguments to plotting of the scalar velocity values (plotted as a mesh) and the vectors (plotted as arrows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first re-open the original video, extract one RGB frame and plot that\n",
    "video_file = \"ngwerere/ngwerere_20191103.mp4\"\n",
    "\n",
    "video = pyorc.Video(video_file, start_frame=0, end_frame=125)\n",
    "# borrow the camera config from the velocimetry results\n",
    "video.camera_config = ds.velocimetry.camera_config\n",
    "\n",
    "da_rgb = video.get_frames(method=\"rgb\")\n",
    "# project the rgb frame\n",
    "da_rgb_proj = da_rgb.frames.project()\n",
    "# plot the first frame (we only have one) without any arguments, default is to use \"local\" mode\n",
    "p = da_rgb_proj[0].frames.plot()\n",
    "\n",
    "# now plot the results on top, we use the mean, because we cannot plot more than 2 dimensions. \n",
    "# Default plotting method is \"quiver\", but \"scatter\" or \"pcolormesh\" is also possible.\n",
    "# We add a nice colorbar to understand the magnitudes.\n",
    "# We give the existing axis handle of the mappable returned from .frames.plot to plot on, and use \n",
    "# some transparency.\n",
    "ds_mean = ds.mean(dim=\"time\", keep_attrs=True)\n",
    "\n",
    "# first a pcolormesh\n",
    "ds_mean.velocimetry.plot.pcolormesh(\n",
    "    ax=p.axes,\n",
    "    alpha=0.3,\n",
    "    cmap=\"rainbow\",\n",
    "    add_colorbar=True,\n",
    "    vmax=0.6\n",
    ")\n",
    "\n",
    "ds_mean.velocimetry.plot(\n",
    "    ax=p.axes,\n",
    "    color=\"w\",\n",
    "    alpha=0.5,\n",
    "    width=0.0015,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6050df61",
   "metadata": {},
   "source": [
    "### Filtering of results\n",
    "Already this looks very promising. But we haven't yet analyzed any of the velocities for spurious values. Even over land we have estimates of velocities, while we would not expect that. We have a set of temporal filters which analyze for spurious values by comparing over time steps, and spatial filters, which compare neighbouring grid cell values to flag spurious values. Let's apply all temporal filters top see what we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e0596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply apply all filters in time domain, this is done by calling .filter_temporal without arguments.\n",
    "ds_filt = ds.velocimetry.filter_temporal()\n",
    "\n",
    "# apply the plot again, let's leave out the scalar values, and make the quivers a bit nicer than before.\n",
    "ds_mean_filt = ds_filt.mean(dim=\"time\", keep_attrs=True)\n",
    "\n",
    "\n",
    "# again the rgb frame first\n",
    "p = da_rgb_proj[0].frames.plot()\n",
    "\n",
    "#...and then filtered velocimetry\n",
    "ds_mean_filt.velocimetry.plot(\n",
    "    ax=p.axes,\n",
    "    alpha=0.4,\n",
    "    cmap=\"rainbow\",\n",
    "    scale=20,\n",
    "    width=0.0015,\n",
    "    norm=Normalize(vmax=0.6, clip=False),\n",
    "    add_colorbar=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3f31ca",
   "metadata": {},
   "source": [
    "Interesting! We see that the velocities become a lot higher on average. Most likely because many spurious velocities are removed. We also see that the velocities seem to be more left-to-right oriented. In part this may be because we applied the `.filter_temporal_angle` method under the hood. This filter removes velocities that are in a direction, far off from the expected direction. The default direction of this filter is always left to right. Therefore take good care of this filter, if you decide to apply `pyorc` in a bottom to top direction.\n",
    "\n",
    "As this stream is very shallow and has lots of obstructions like rocks that the water goes around, the application of this filter may have removed many velocities that were actually correct. Let's do the filtering again, but whilst leaving out the angular filter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e713b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply all filters in time domain except for the angle filter, this is done by calling .filter_temporal without arguments.\n",
    "import numpy as np\n",
    "ds_filt2 = ds.velocimetry.filter_temporal(kwargs_angle=dict(angle_tolerance=0.5*np.pi))\n",
    "ds_filt2.velocimetry.filter_spatial(filter_nan=False, inplace=True, kwargs_median=dict(wdw=2))\n",
    "# apply the plot again, let's leave out the scalr values, and make the quivers a bit nicer than before.\n",
    "\n",
    "ds_mean_filt2 = ds_filt2.mean(dim=\"time\", keep_attrs=True)\n",
    "\n",
    "# again the rgb frame first\n",
    "p = da_rgb_proj[0].frames.plot()\n",
    "\n",
    "#...and then filtered velocimetry\n",
    "ds_mean_filt2.velocimetry.plot(\n",
    "    ax=p.axes,\n",
    "    alpha=0.4,\n",
    "    cmap=\"rainbow\",\n",
    "    scale=20,\n",
    "    width=0.0015,\n",
    "    norm=Normalize(vmax=0.6, clip=False),\n",
    "    add_colorbar=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0192f4d",
   "metadata": {},
   "source": [
    "It looks more natural. Check for instance the pattern around the rock on the left side. Now we can also plot in a geographical view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97952713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again the rgb frame first. But now we use the \"geographical\" mode to plot on a map\n",
    "p = da_rgb_proj[0].frames.plot(mode=\"geographical\")\n",
    "\n",
    "#...and then filtered velocimetry again, but also geographical\n",
    "ds_mean_filt2.velocimetry.plot(\n",
    "    ax=p.axes,\n",
    "    mode=\"geographical\",\n",
    "    alpha=0.4,\n",
    "    cmap=\"rainbow\",\n",
    "    scale=20,\n",
    "    width=0.0015,\n",
    "    norm=Normalize(vmax=0.6, clip=False),\n",
    "    add_colorbar=True\n",
    ")\n",
    "\n",
    "# for fun, let's also add a satellite background from cartopy\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import cartopy.crs as ccrs\n",
    "tiles = cimgt.GoogleTiles(style=\"satellite\")\n",
    "p.axes.add_image(tiles, 19)\n",
    "# zoom out a little bit so that we can actually see a bit\n",
    "p.axes.set_extent([\n",
    "    da_rgb_proj.lon.min() - 0.00005,\n",
    "    da_rgb_proj.lon.max() + 0.00005,\n",
    "    da_rgb_proj.lat.min() - 0.00005,\n",
    "    da_rgb_proj.lat.max() + 0.00005],\n",
    "    crs=ccrs.PlateCarree()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43317e4",
   "metadata": {},
   "source": [
    "### Immersive and intuitive augmented reality\n",
    "And now the most beautiful plot you can make with pyorc: an augmented reality view. For this, we need an unprojected rgb frame and supply the `mode=\"camera\"` keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again the rgb frame first, but now the unprojected one. Now we use the \"camera\" mode to plot the camera perspective\n",
    "p = da_rgb[0].frames.plot(mode=\"camera\")\n",
    "\n",
    "#...and then filtered velocimetry again, but also camera. This gives us an augmented reality view. The quiver scale \n",
    "# needs to be adapted to fit in the screen properly\n",
    "ds_mean_filt2.velocimetry.plot(\n",
    "    ax=p.axes,\n",
    "    mode=\"camera\",\n",
    "    alpha=0.4,\n",
    "    cmap=\"rainbow\",\n",
    "    scale=200,\n",
    "    width=0.0015,\n",
    "    norm=Normalize(vmin=0., vmax=0.6, clip=False),\n",
    "    add_colorbar=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096fd506",
   "metadata": {},
   "source": [
    "### Store the final filtered results\n",
    "Let's also store the filtered velocities in a separate file. To ensure it remains really small, we can use the `.set_encoding` method first, to ensure the variables are encoded to integer values before storing. This makes the file nice and small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993aab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_filt2.velocimetry.set_encoding()\n",
    "ds_filt2.to_netcdf(\"ngwerere_filtered.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bba8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
